{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "nervous-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "binary-senior",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "norwegian-depth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available. If you are using Google Colab, change the runtime to GPU, otherwise training will take too long.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print('GPU acceleration is available and will be used :-)')\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print('GPU is not available. If you are using Google Colab, change the runtime to GPU, otherwise training will '\n",
    "          'take too long.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "numerical-gateway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 lines removed\n",
      "Train set 131,438\n",
      "0 lines removed\n",
      "Test set 7,801\n"
     ]
    }
   ],
   "source": [
    "from data_util import generate_train_validation_test_files\n",
    "\n",
    "generate_train_validation_test_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "limited-criminal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulabartabajo/miniconda3/envs/chatbot/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/Users/paulabartabajo/miniconda3/envs/chatbot/lib/python3.7/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/Users/paulabartabajo/miniconda3/envs/chatbot/lib/python3.7/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 999\n",
      "Validation set size: 999\n",
      "Vocab size:  2598\n"
     ]
    }
   ],
   "source": [
    "from data_util import DataWrapper\n",
    "\n",
    "# Dataset objects\n",
    "dw = DataWrapper()\n",
    "train_ds, validation_ds, test_ds = dw.get_datasets(\n",
    "    train_size=999,\n",
    "    val_size=999,\n",
    "    use_glove=True\n",
    ")\n",
    "print(f'Train set size: {len(train_ds):,}')\n",
    "print(f'Validation set size: {len(validation_ds):,}')\n",
    "print('Vocab size: ', dw.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "incoming-literacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example \n",
      "-------\n",
      "tensor([[  2,  39,  14,  ...,   3,   1,   1],\n",
      "        [  2,  45,   8,  ...,   3,   1,   1],\n",
      "        [  2,  39,  18,  ...,   3,   1,   1],\n",
      "        ...,\n",
      "        [  2,  39,  14,  ...,   1,   1,   1],\n",
      "        [  2,  45,  54,  ...,   1,   1,   1],\n",
      "        [  2,   4,  26,  ..., 754,   0,   3]])\n",
      "tensor([119, 119, 119, 118, 116, 116, 116, 117, 116, 115, 115, 116, 116, 117,\n",
      "        117, 116, 116, 115, 115, 121])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulabartabajo/miniconda3/envs/chatbot/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/Users/paulabartabajo/miniconda3/envs/chatbot/lib/python3.7/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# DataLoader objects\n",
    "train_iter, validation_iter, test_iter = dw.get_dataloaders(\n",
    "    train_ds, validation_ds, test_ds,\n",
    "    batch_size=2400,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "x = next(iter(train_iter))\n",
    "print('Example \\n-------')\n",
    "print(x.src[0])\n",
    "print(x.src[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "previous-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from model import Seq2seqRNN\n",
    "\n",
    "vocab_size = dw.vocab_size\n",
    "embedding_dim = dw.embedding_dim\n",
    "hidden_dim = 256\n",
    "n_layers = 3\n",
    "n_directions_encoder = 2\n",
    "model = Seq2seqRNN(vocab_size,\n",
    "                   embedding_dim,\n",
    "                   hidden_dim,\n",
    "                   n_layers,\n",
    "                   n_directions_encoder,\n",
    "                   dropout=0.2,\n",
    "                   pretrained_embeddings=dw.embeddings,\n",
    "                   freeze_embeddings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "reduced-assembly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 6,233,854 parameters\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from model import count_parameters\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-burner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
