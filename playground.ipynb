{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nervous-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vanilla-comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available. If you are using Google Colab, change the runtime to GPU, otherwise training will take too long.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print('GPU acceleration is available and will be used :-)')\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print('GPU is not available. If you are using Google Colab, change the runtime to GPU, otherwise training will '\n",
    "          'take too long.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "moderate-plane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-01-27 21:16:43--  https://s3.amazonaws.com/datasets.huggingface.co/personachat/personachat_self_original.json\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.251.30\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.251.30|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 209850483 (200M) [application/json]\n",
      "Saving to: ‘./data/personachat_self_original.json.1’\n",
      "\n",
      "personachat_self_or 100%[===================>] 200.13M  5.70MB/s    in 36s     \n",
      "\n",
      "2021-01-27 21:17:19 (5.60 MB/s) - ‘./data/personachat_self_original.json.1’ saved [209850483/209850483]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!sh download_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "numerical-gateway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 lines removed\n",
      "Train set 131,438\n",
      "0 lines removed\n",
      "Test set 7,801\n"
     ]
    }
   ],
   "source": [
    "from data_util import generate_train_validation_test_files\n",
    "\n",
    "generate_train_validation_test_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "limited-criminal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 99\n",
      "Validation set size: 99\n",
      "Vocab size:  500\n"
     ]
    }
   ],
   "source": [
    "from data_util import DataWrapper\n",
    "\n",
    "# Dataset objects\n",
    "dw = DataWrapper()\n",
    "train_ds, val_ds, test_ds = dw.get_datasets(\n",
    "    train_size=99,\n",
    "    val_size=99,\n",
    "    use_glove=True\n",
    ")\n",
    "print(f'Train set size: {len(train_ds):,}')\n",
    "print(f'Validation set size: {len(val_ds):,}')\n",
    "print('Vocab size: ', dw.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alternative-attendance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example \n",
      "-------\n",
      "tensor([[  2,  34,  10,  21,  14,   6,  48,   8,   4,  27, 116, 119,  11,  12,\n",
      "          43, 189, 188,  11, 229,  24, 224,   9,   6, 215,  80,  67, 197,   5,\n",
      "         101,  16, 118,  26,  13,  40,  78,   9,   4,  15,  20,  25,  13, 146,\n",
      "           4,  22,  11,  12, 142,  53,  43, 293,   9,   4,  51, 278, 208,  70,\n",
      "           4,  15,  31, 159, 249, 101,   9,  23,  54, 345,   5,  70,   4,  57,\n",
      "          24, 323,  73,   4, 351, 302,  24, 301, 341, 311,  20, 374,  54,  98,\n",
      "           5,  12,   6,  18,   7,  40, 223,  53,  45,  26, 163,   8,  28,  12,\n",
      "          31,   5,  32,   4,  12,  18,   7,  40, 147, 161,  23,  16,  86,   4,\n",
      "         106, 389,   9,  30,  16,  39,  40, 147,  11, 106,   8,  28, 112,  18,\n",
      "          11, 484, 265, 478, 481,   5,  12,   6,  18,  79,  40, 459,   8,  28,\n",
      "          22, 445,  53, 468,  19, 444,   9,  12,   6,  18, 105,   0,  25,  41,\n",
      "           8,   4, 420,   4,  15,  82,  11,  12,  43, 142,   9,   4,  15,  82,\n",
      "          11,  68,  62,   5,  30,  14,   6, 142,   8,  28, 420,   4, 294,  37,\n",
      "          43,   0,   5,  12,   6,  51, 133,   0,  25, 128,   8,   3],\n",
      "        [  2,  66,  65,  10,   4,  27,  83,  11,  13,  40, 182, 202,  19, 221,\n",
      "           9,  61, 210,   8,   4,  57,  33,  83,  11,  17, 134, 177,  75, 231,\n",
      "           7, 183,   9,  26, 253,   5,   4,  38,  11, 268,  11,  66,   9, 270,\n",
      "          13, 250,  33, 276,  65,  17, 126,  20, 242,   4,  27, 328,  50, 167,\n",
      "           5, 104,  44, 266,  35, 112,  58, 135,  65,  13,  50, 126,   9, 335,\n",
      "           5,   4,  38,  50,  91,  20, 260,   4,  57,  47,  13,  85,  91, 340,\n",
      "           9,   4,  88,   7,  50, 186,  10, 412,  10, 426,  86,  50,   9, 402,\n",
      "           4,  37, 380, 418,  59,   4,  15, 409,  11, 425,  13, 385,  24, 382,\n",
      "           9, 431,  10,  95, 463,  90, 138,  53,  29,   8,   0,   5, 473, 138,\n",
      "         123, 491, 499, 435,  25,   7, 190, 489,  64,   9,  18,   6,   0,   0,\n",
      "         138, 307,   8,   0,   5,   6,  37,  31, 195, 152,   7,   0,   0,  53,\n",
      "           6,  37,  89,   0,   9, 150,   7,   0,   0,   5,   4,   0, 474,  99,\n",
      "           5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2,  34,  10,  21,  14,   6,  48,   8,   4,  27, 116, 119,  11,  12,\n",
      "          43, 189, 188,  11, 229,  24, 224,   9,   6, 215,  80,  67, 197,   5,\n",
      "         101,  16, 118,  26,  13,  40,  78,   9,   4,  15,  20,  25,  13, 146,\n",
      "           4,  22,  11,  12, 142,  53,  43, 293,   9,   4,  51, 278, 208,  70,\n",
      "           4,  15,  31, 159, 249, 101,   9,  23,  54, 345,   5,  70,   4,  57,\n",
      "          24, 323,  73,   4, 351, 302,  24, 301, 341, 311,  20, 374,  54,  98,\n",
      "           5,  12,   6,  18,   7,  40, 223,  53,  45,  26, 163,   8,  28,  12,\n",
      "          31,   5,  32,   4,  12,  18,   7,  40, 147, 161,  23,  16,  86,   4,\n",
      "         106, 389,   9,  30,  16,  39,  40, 147,  11, 106,   8,  28, 112,  18,\n",
      "          11, 484, 265, 478, 481,   5,  12,   6,  18,  79,  40, 459,   8,  28,\n",
      "          22, 445,  53, 468,  19, 444,   9,  12,   6,  18, 105,   0,  25,  41,\n",
      "           8,   4, 420,   4,  15,  82,  11,  12,  43, 142,   5,   3,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  2, 162,  86,  90,  24,   7, 122, 121,  10,   7, 122, 121,   5, 273,\n",
      "          20, 113,  20,  23,  16,   7,  36, 267,  25,  13, 216, 285,  46,   9,\n",
      "         102,   5,   4,  15, 359,  10, 105,  11, 309,  17, 325,  10,  19,   4,\n",
      "          15,   7, 306, 314,   9,   4,  37, 176,   5,   4,  15,  31,  10,   6,\n",
      "          37,  74,  49,  24,  43, 111, 416,   8,  30, 358,   8,   4,  22, 111,\n",
      "          10,  35, 342,  49, 198,   4,  12,  31,  22,  13, 457,  10,   4, 369,\n",
      "           4,  71,   7, 379, 196,   5,   4, 393,  46,  24,   7,  67, 417, 423,\n",
      "           9,   4, 143,  91,   5,   4,  12,  31,  89, 375,  42, 471,   5, 287,\n",
      "          18,  61, 446,   9,  33, 454,  43, 450,  42, 483,  19,   6, 165, 198,\n",
      "         123, 137,  20,   0,  17,   0,  24,  17,   0,  59,  69,   5,   5,   9,\n",
      "           0,  10,   0,   0,   0,  10,  23,  54,  30, 162,   0,   0,  44,  17,\n",
      "           0,   9,   4, 219,   0,   5,   0,  53,   0,   5,   3,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1]])\n",
      "tensor([194, 170, 166, 165])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulabartabajo/miniconda3/envs/chatbot_py3.6/lib/python3.6/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/Users/paulabartabajo/miniconda3/envs/chatbot_py3.6/lib/python3.6/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# DataLoader objects\n",
    "train_iter, val_iter, test_iter = dw.get_dataloaders(\n",
    "    train_ds, val_ds, test_ds,\n",
    "    batch_size=2400,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "x = next(iter(train_iter))\n",
    "print('Example \\n-------')\n",
    "print(x.src[0])\n",
    "print(x.src[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "voluntary-credit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 5,484,868 parameters\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from model import Seq2seqRNN, count_parameters\n",
    "\n",
    "vocab_size = dw.vocab_size\n",
    "embedding_dim = dw.embedding_dim\n",
    "hidden_dim = 256\n",
    "n_layers = 3\n",
    "n_directions_encoder = 2\n",
    "model = Seq2seqRNN(vocab_size,\n",
    "                   embedding_dim,\n",
    "                   hidden_dim,\n",
    "                   n_layers,\n",
    "                   n_directions_encoder,\n",
    "                   dropout=0.2,\n",
    "                   pretrained_embeddings=dw.embeddings,\n",
    "                   freeze_embeddings=False)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "gothic-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import Seq2seqRNNTrainer\n",
    "\n",
    "trainer = Seq2seqRNNTrainer(model,\n",
    "                            train_iter,\n",
    "                            val_iter,\n",
    "                            learning_rate=3e-4,\n",
    "                            pad_token_id=dw.pad_token_id,\n",
    "                            gradient_clip=99999,\n",
    "                            teacher_forcing=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-affect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6815f8a3f2ff4d29bab1cd97556f49f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ade9034126471a8f6b00a025434ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train loss: 4.8019, Val loss: 4.2843, Train ppl: 121.7, Val ppl: 72.6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b285fd21d5428184058be0950eb8c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2599d19917c5400f86fe4d707b7b9a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train loss: 4.7110, Val loss: 4.2226, Train ppl: 111.2, Val ppl: 68.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5edc956c692e4dba93978f7dcf31d152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "trainer.train(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-beijing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
