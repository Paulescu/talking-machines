{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "younger-quarterly",
   "metadata": {},
   "source": [
    "# Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# git clone https://github.com/Paulescu/talking-machines.git\n",
    "# mv talking-machines/* .\n",
    "# rm -r talking-machines\n",
    "# pip install -r requirements_py3.6.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nervous-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "quantitative-alexander",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in local\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Running in Colab')\n",
    "    CHECKPOINT_DIR = Path('/content/drive/MyDrive/chatbot-course')\n",
    "\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "else:\n",
    "    print('Running in local')\n",
    "    CHECKPOINT_DIR = Path('./checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vanilla-comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available. If you are using Google Colab, change the runtime to GPU, otherwise training will take too long.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print('GPU acceleration is available and will be used :-)')\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print('GPU is not available. If you are using Google Colab, change the runtime to GPU, otherwise training will '\n",
    "          'take too long.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-valve",
   "metadata": {},
   "source": [
    "# Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "moderate-plane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-01-27 21:16:43--  https://s3.amazonaws.com/datasets.huggingface.co/personachat/personachat_self_original.json\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.251.30\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.251.30|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 209850483 (200M) [application/json]\n",
      "Saving to: ‘./data/personachat_self_original.json.1’\n",
      "\n",
      "personachat_self_or 100%[===================>] 200.13M  5.70MB/s    in 36s     \n",
      "\n",
      "2021-01-27 21:17:19 (5.60 MB/s) - ‘./data/personachat_self_original.json.1’ saved [209850483/209850483]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!sh download_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "numerical-gateway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a635481b567f49ae910d4d1fe523036c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17878 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 lines removed\n",
      "Train set 131,438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe58dcc524614217a4f13af71f6fc518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 lines removed\n",
      "Test set 7,801\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from utils.data import generate_train_validation_test_files\n",
    "\n",
    "generate_train_validation_test_files(autocorrect=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "psychological-gateway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 18,693\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from utils.vocab import get_vocab, WordVocab\n",
    "from utils.constants import *\n",
    "\n",
    "vocab = WordVocab(Path(DATA_DIR) / 'train.csv')\n",
    "vocab.load_glove_vectors()\n",
    "vocab.save(Path(ARTIFACTS_DIR) / f'vocab_{vocab.size}')\n",
    "print(f'Vocab size: {vocab.size:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "respected-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from utils.data import get_datasets\n",
    "\n",
    "train_ds, val_ds, test_ds = get_datasets(vocab, train_size=10000, val_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "alternative-attendance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example \n",
      "-------\n",
      "tensor([[  2,  35,   6,  ..., 138,   8,   3],\n",
      "        [  2,  35,   6,  ...,  90,   4,   3],\n",
      "        [  2,  35,  55,  ...,   3,   1,   1],\n",
      "        ...,\n",
      "        [  2,  86,  55,  ...,   1,   1,   1],\n",
      "        [  2,  35,  55,  ...,   1,   1,   1],\n",
      "        [  2,  46,   6,  ...,   1,   1,   1]])\n",
      "tensor([132, 132, 130, 130, 128, 128, 124, 124, 122, 122, 123, 123, 122, 121,\n",
      "        121, 119, 119, 117])\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from utils.data import get_dataloaders\n",
    "\n",
    "train_iter, val_iter, test_iter = get_dataloaders(\n",
    "    train_ds, val_ds, test_ds,\n",
    "    batch_size=2400,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "x = next(iter(train_iter))\n",
    "print('Example \\n-------')\n",
    "print(x.src[0])\n",
    "print(x.src[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "voluntary-credit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 11,979,769 parameters\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from model import Seq2seqRNN, count_parameters\n",
    "\n",
    "hidden_dim = 256\n",
    "n_layers = 3\n",
    "n_directions_encoder = 2\n",
    "model = Seq2seqRNN(vocab.size,\n",
    "                   vocab.vectors_dim,\n",
    "                   hidden_dim,\n",
    "                   n_layers,\n",
    "                   n_directions_encoder,\n",
    "                   dropout=0.2,\n",
    "                   pretrained_embeddings=vocab.vectors,\n",
    "                   freeze_embeddings=False)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "gothic-clothing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f5319d8eb349debb7609e7922d4910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a14a6fbe7c5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                             checkpoint_dir=CHECKPOINT_DIR)\n\u001b[1;32m     12\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/src/online-courses/advanced-nlp-chatbot/train.py\u001b[0m in \u001b[0;36mtrain_test_loop\u001b[0;34m(self, n_epochs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/online-courses/advanced-nlp-chatbot/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/online-courses/advanced-nlp-chatbot/train.py\u001b[0m in \u001b[0;36miteration\u001b[0;34m(self, epoch, dataloader, dataset_size, train)\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0;31m# backward step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m                     \u001b[0;31m# torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/chatbot_py3.6/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/chatbot_py3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from train import Seq2seqRNNTrainer\n",
    "\n",
    "trainer = Seq2seqRNNTrainer(model,\n",
    "                            train_iter,\n",
    "                            val_iter,\n",
    "                            learning_rate=3e-4,\n",
    "                            pad_token_id=vocab.pad_token_id,\n",
    "                            gradient_clip=99999,\n",
    "                            teacher_forcing=0.5,\n",
    "                            checkpoint_dir=CHECKPOINT_DIR)\n",
    "n_epochs = 2\n",
    "trainer.train_test_loop(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "abstract-beijing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7091ec0ee6943da9c50ffdd548bac77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a30c22371b4e84832ffef4572a3a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train loss: 5.7879, Val loss: 4.7615, Train ppl: 326.3, Val ppl: 116.9\n",
      "checkpoints/0193b9c0-6544-11eb-b0e5-acbc32b70c09/1.ckpt was saved\n",
      "checkpoints/0193b9c0-6544-11eb-b0e5-acbc32b70c09/params.json file was saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d7c80478b14fffb12d7685850b60b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff99563a553414298986f86b2c72b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train loss: 5.1757, Val loss: 4.3103, Train ppl: 176.9, Val ppl: 74.5\n",
      "checkpoints/0193b9c0-6544-11eb-b0e5-acbc32b70c09/2.ckpt was saved\n",
      "checkpoints/0193b9c0-6544-11eb-b0e5-acbc32b70c09/params.json file was saved\n"
     ]
    }
   ],
   "source": [
    "trainer.load(run_id=trainer.run_id, epoch=1)\n",
    "\n",
    "n_epochs = 2\n",
    "trainer.train_test_loop(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "missing-yemen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62fc82699594e019338ff3d05ca029e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe8a3fc286f489d83a88523159da806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train loss: 4.9722, Val loss: 4.1971, Train ppl: 144.3, Val ppl: 66.5\n",
      "checkpoints/0193b9c0-6544-11eb-b0e5-acbc32b70c09/3.ckpt was saved\n",
      "checkpoints/0193b9c0-6544-11eb-b0e5-acbc32b70c09/params.json file was saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857861c2aa5d445b913c02ea65b8f1f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8efd4f826d64e78928dbca5cf4c8bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train loss: 4.8659, Val loss: 4.1958, Train ppl: 129.8, Val ppl: 66.4\n",
      "checkpoints/0193b9c0-6544-11eb-b0e5-acbc32b70c09/4.ckpt was saved\n",
      "checkpoints/0193b9c0-6544-11eb-b0e5-acbc32b70c09/params.json file was saved\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2\n",
    "trainer.train_test_loop(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-request",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
